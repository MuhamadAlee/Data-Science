{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7hv79aFsoXl"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "Vj1-yeLwsoe3",
    "outputId": "b17ae425-168b-448f-9967-2b76b5c34532"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.5</th>\n",
       "      <th>1.4</th>\n",
       "      <th>0.2</th>\n",
       "      <th>Iris-setosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     5.1  3.5  1.4  0.2     Iris-setosa\n",
       "0    4.9  3.0  1.4  0.2     Iris-setosa\n",
       "1    4.7  3.2  1.3  0.2     Iris-setosa\n",
       "2    4.6  3.1  1.5  0.2     Iris-setosa\n",
       "3    5.0  3.6  1.4  0.2     Iris-setosa\n",
       "4    5.4  3.9  1.7  0.4     Iris-setosa\n",
       "..   ...  ...  ...  ...             ...\n",
       "144  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "145  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "146  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "147  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "148  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[149 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"iris.data\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "moC7ISYDsoku"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:4].values\n",
    "y = dataset.iloc[:,4].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "Y = pd.get_dummies(y1).values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "KZ8X63HVswnh",
    "outputId": "fe05700f-99cd-4231-ba24-0261fa6a5bc7"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4,input_shape=(4,), activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "6QDB8sznsw1h",
    "outputId": "ca4de29f-c8a7-4a76-9c73-3b4be114e3ec"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Rs1GTTaTsxCQ",
    "outputId": "17727603-8120-4350-f8ea-e02e22855429"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alee\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.3025 - accuracy: 0.3109\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 4.9086 - accuracy: 0.3109\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 4.5620 - accuracy: 0.3109\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 4.2708 - accuracy: 0.3109\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 4.0126 - accuracy: 0.3109\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 3.7635 - accuracy: 0.3109\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 163us/step - loss: 3.5303 - accuracy: 0.3109\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 3.3206 - accuracy: 0.3109\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 3.1102 - accuracy: 0.3109\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 2.9235 - accuracy: 0.3109\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 2.7537 - accuracy: 0.3109\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 2.5852 - accuracy: 0.3109\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 2.4365 - accuracy: 0.3109\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 2.2986 - accuracy: 0.3109\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 2.1727 - accuracy: 0.3109\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 185us/step - loss: 2.0601 - accuracy: 0.3109\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 1.9457 - accuracy: 0.3109\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 1.8520 - accuracy: 0.3109\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 1.7583 - accuracy: 0.3109\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 1.6772 - accuracy: 0.3109\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 302us/step - loss: 1.5955 - accuracy: 0.3109\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 1.5222 - accuracy: 0.3109\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 1.4560 - accuracy: 0.3109\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 1.3918 - accuracy: 0.3109\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 1.3351 - accuracy: 0.3109\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 1.2840 - accuracy: 0.3109\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 1.2366 - accuracy: 0.3109\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 1.1962 - accuracy: 0.3109\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 1.1571 - accuracy: 0.3025\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 1.1224 - accuracy: 0.3025\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 1.0908 - accuracy: 0.3109\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 1.0628 - accuracy: 0.3109\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 1.0367 - accuracy: 0.3277\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 1.0138 - accuracy: 0.3529\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.9925 - accuracy: 0.4034\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 0.9727 - accuracy: 0.5126\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 269us/step - loss: 0.9535 - accuracy: 0.5462\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.9360 - accuracy: 0.5798\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.9201 - accuracy: 0.6807\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 0.9069 - accuracy: 0.7227\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 0.8921 - accuracy: 0.7731\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.8784 - accuracy: 0.7983\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.8663 - accuracy: 0.8319\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.8545 - accuracy: 0.8739\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.8444 - accuracy: 0.8908\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.8349 - accuracy: 0.8992\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 0.8267 - accuracy: 0.9076\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.8192 - accuracy: 0.9160\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.8129 - accuracy: 0.9076\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.8043 - accuracy: 0.9076\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 0.7975 - accuracy: 0.9076\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 0.7907 - accuracy: 0.9160\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.7835 - accuracy: 0.9160\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.7764 - accuracy: 0.9076\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.7704 - accuracy: 0.9076\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.7636 - accuracy: 0.9076\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.7566 - accuracy: 0.9076\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.7505 - accuracy: 0.9076\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.7448 - accuracy: 0.9160\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.7385 - accuracy: 0.9160\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.7322 - accuracy: 0.9160\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.7266 - accuracy: 0.9160\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 0.7206 - accuracy: 0.9244\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 0.7155 - accuracy: 0.9160\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.7105 - accuracy: 0.9244\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 0.7052 - accuracy: 0.9328\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 0.7000 - accuracy: 0.9244\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6951 - accuracy: 0.9160\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6902 - accuracy: 0.9160\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6859 - accuracy: 0.9244\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6807 - accuracy: 0.9244\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6764 - accuracy: 0.9412\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6717 - accuracy: 0.9328\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6673 - accuracy: 0.9244\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 0.6633 - accuracy: 0.9328\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6593 - accuracy: 0.9328\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6551 - accuracy: 0.9328\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 235us/step - loss: 0.6508 - accuracy: 0.9328\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 202us/step - loss: 0.6475 - accuracy: 0.9328\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6434 - accuracy: 0.9244\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6399 - accuracy: 0.9328\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6362 - accuracy: 0.9328\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6327 - accuracy: 0.9244\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 202us/step - loss: 0.6292 - accuracy: 0.9412\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 0.6258 - accuracy: 0.9244\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 134us/step - loss: 0.6227 - accuracy: 0.9412\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 0.6192 - accuracy: 0.9412\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 134us/step - loss: 0.6159 - accuracy: 0.9328\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 0.6123 - accuracy: 0.9412\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 134us/step - loss: 0.6105 - accuracy: 0.9580\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 134us/step - loss: 0.6062 - accuracy: 0.9496\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 134us/step - loss: 0.6031 - accuracy: 0.9328\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 0.6000 - accuracy: 0.9496\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 134us/step - loss: 0.5967 - accuracy: 0.9496\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 0.5939 - accuracy: 0.9496\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 134us/step - loss: 0.5905 - accuracy: 0.9496\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 0.5877 - accuracy: 0.9496\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 0.5851 - accuracy: 0.9496\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 168us/step - loss: 0.5817 - accuracy: 0.9412\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 134us/step - loss: 0.5793 - accuracy: 0.9580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19466c8ef48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=10, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_p6yilvas2kZ"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "WrgLET2Ns22J",
    "outputId": "a53a01f5-1119-4cc9-cad7-469eafb7a247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "[[12  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N7m3PcNvs3CZ",
    "outputId": "3753b0d3-eeaa-4d5a-9a10-824160a0686b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_class,y_pred_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2z0VjOco1zhs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Multiple Classificaiton using IRIS Dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
